# backend/rag/kg_enhancer.py (æ–°æ–‡ä»¶)
"""
çŸ¥è¯†å›¾è°±å¢å¼ºå™¨ - æ¸…ç†å’Œä¸°å¯Œæå–çš„å›¾è°±
"""
import logging
from typing import Dict, List, Any
from collections import Counter
 
logger = logging.getLogger(__name__)
 
 
class KGEnhancer:
    """çŸ¥è¯†å›¾è°±å¢å¼ºå™¨"""
    
    def __init__(self):
        # åœç”¨è¯ï¼ˆè¿‡æ»¤æ— ç”¨å®ä½“ï¼‰
        self.stopwords = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at',
            'to', 'for', 'of', 'with', 'by', 'from', 'as', 'is', 'was',
            'are', 'were', 'been', 'be', 'have', 'has', 'had', 'do',
            'does', 'did', 'will', 'would', 'should', 'could', 'may',
            'might', 'must', 'can', 'this', 'that', 'these', 'those'
        }
    
    def enhance(self, kg_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¢å¼ºçŸ¥è¯†å›¾è°±
        
        1. æ¸…ç†æ— æ•ˆå®ä½“
        2. åˆå¹¶ç›¸ä¼¼å®ä½“
        3. è®¡ç®—é‡è¦æ€§åˆ†æ•°
        4. æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        """
        logger.info("ğŸ”§ Enhancing knowledge graph...")
        
        entities = kg_data.get("entities", [])
        relationships = kg_data.get("relationships", [])
        
        # 1. æ¸…ç†å®ä½“
        cleaned_entities = self._clean_entities(entities)
        
        # 2. æ¸…ç†å…³ç³»
        cleaned_relationships = self._clean_relationships(relationships, cleaned_entities)
        
        # 3. è®¡ç®—å®ä½“é‡è¦æ€§
        entity_importance = self._calculate_importance(cleaned_entities, cleaned_relationships)
        
        # 4. æ·»åŠ é‡è¦æ€§åˆ†æ•°
        for entity in cleaned_entities:
            entity_text = entity["text"]
            entity["importance"] = entity_importance.get(entity_text, 1.0)
        
        # 5. æ’åºï¼ˆæŒ‰é‡è¦æ€§ï¼‰
        cleaned_entities.sort(key=lambda x: x.get("importance", 0), reverse=True)
        
        # 6. ç»Ÿè®¡ä¿¡æ¯
        stats = self._calculate_statistics(cleaned_entities, cleaned_relationships)
        
        logger.info(f"âœ… Enhanced: {len(cleaned_entities)} entities, {len(cleaned_relationships)} relationships")
        
        return {
            "entities": cleaned_entities,
            "relationships": cleaned_relationships,
            "statistics": stats
        }
    
    def _clean_entities(self, entities: List[Dict]) -> List[Dict]:
        """æ¸…ç†å®ä½“"""
        cleaned = []
        
        for entity in entities:
            text = entity.get("text", "").strip()
            
            # è·³è¿‡ç©ºå®ä½“
            if not text:
                continue
            
            # è·³è¿‡è¿‡çŸ­çš„å®ä½“
            if len(text) < 2:
                continue
            
            # è·³è¿‡åœç”¨è¯
            if text.lower() in self.stopwords:
                continue
            
            # è·³è¿‡çº¯æ•°å­—ï¼ˆæ²¡æœ‰ä¸Šä¸‹æ–‡çš„ï¼‰
            if text.replace('.', '').replace(',', '').replace('$', '').isdigit() and not entity.get("context"):
                continue
            
            cleaned.append(entity)
        
        return cleaned
    
    def _clean_relationships(self, relationships: List[Dict], valid_entities: List[Dict]) -> List[Dict]:
        """æ¸…ç†å…³ç³»ï¼ˆç¡®ä¿sourceå’Œtargetéƒ½å­˜åœ¨ï¼‰"""
        # åˆ›å»ºæœ‰æ•ˆå®ä½“é›†åˆ
        valid_entity_texts = {e["text"] for e in valid_entities}
        
        cleaned = []
        for rel in relationships:
            source = rel.get("source", "").strip()
            target = rel.get("target", "").strip()
            
            # æ£€æŸ¥sourceå’Œtargetæ˜¯å¦åœ¨æœ‰æ•ˆå®ä½“ä¸­
            if source in valid_entity_texts and target in valid_entity_texts:
                cleaned.append(rel)
        
        return cleaned
    
    def _calculate_importance(self, entities: List[Dict], relationships: List[Dict]) -> Dict[str, float]:
        """è®¡ç®—å®ä½“é‡è¦æ€§ï¼ˆåŸºäºè¿æ¥æ•°ï¼‰"""
        importance = Counter()
        
        # ç»Ÿè®¡æ¯ä¸ªå®ä½“åœ¨å…³ç³»ä¸­å‡ºç°çš„æ¬¡æ•°
        for rel in relationships:
            source = rel.get("source", "")
            target = rel.get("target", "")
            
            importance[source] += 1
            importance[target] += 1
        
        # å½’ä¸€åŒ–ï¼ˆè½¬æ¢ä¸º0-10çš„åˆ†æ•°ï¼‰
        if importance:
            max_count = max(importance.values())
            return {
                entity: min(10, (count / max_count) * 10)
                for entity, count in importance.items()
            }
        
        return {}
    
    def _calculate_statistics(self, entities: List[Dict], relationships: List[Dict]) -> Dict:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        # å®ä½“ç±»å‹åˆ†å¸ƒ
        entity_types = Counter(e.get("type", "UNKNOWN") for e in entities)
        
        # å…³ç³»ç±»å‹åˆ†å¸ƒ
        relation_types = Counter(r.get("relation", "unknown") for r in relationships)
        
        # æœ€é‡è¦çš„å®ä½“
        top_entities = sorted(
            entities,
            key=lambda x: x.get("importance", 0),
            reverse=True
        )[:10]
        
        return {
            "total_entities": len(entities),
            "total_relationships": len(relationships),
            "entity_types": dict(entity_types),
            "relation_types": dict(relation_types),
            "top_entities": [
                {
                    "text": e["text"],
                    "type": e["type"],
                    "importance": e.get("importance", 0)
                }
                for e in top_entities
            ]
        }
 
 
# å…¨å±€å®ä¾‹
kg_enhancer = KGEnhancer()