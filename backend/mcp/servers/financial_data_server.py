# backend/mcp/servers/financial_data_server.py
"""
Financial Data MCP Server - ç»Ÿä¸€é‡‘èæ•°æ®è®¿é—®æ¥å£
æä¾›æ ‡å‡†åŒ–çš„è‚¡ç¥¨æ•°æ®ã€å¸‚åœºæ•°æ®ã€åŸºæœ¬é¢æ•°æ®è®¿é—®
"""
import asyncio
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
import json
 
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent, ImageContent, EmbeddedResource
 
from backend.mcp.adapters.yahoo_adapter import YahooFinanceAdapter
from backend.mcp.adapters.alpha_vantage_adapter import AlphaVantageAdapter
from backend.mcp.config.mcp_settings import mcp_settings
 
logger = logging.getLogger(__name__)
 
 
class FinancialDataMCPServer:
    """
    é‡‘èæ•°æ®MCPæœåŠ¡å™¨
    
    åŠŸèƒ½ï¼š
    1. ç»Ÿä¸€å¤šä¸ªæ•°æ®æºï¼ˆYahoo Finance, Alpha Vantageç­‰ï¼‰
    2. æ™ºèƒ½è·¯ç”±å’Œæ•…éšœè½¬ç§»
    3. æ•°æ®ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–
    4. æ ‡å‡†åŒ–é”™è¯¯å¤„ç†
    """
    
    def __init__(self):
        self.server = Server("financial-data-mcp")
        self.adapters: Dict[str, Any] = {
            "yahoo": YahooFinanceAdapter(),
            "alpha_vantage": AlphaVantageAdapter(),
        }
        self.cache: Dict[str, tuple] = {}  # {cache_key: (data, timestamp)}
        self._register_tools()
        
    def _register_tools(self):
        """æ³¨å†Œæ‰€æœ‰å¯ç”¨å·¥å…·"""
        
        @self.server.list_tools()
        async def list_tools() -> List[Tool]:
            """åˆ—å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·"""
            return [
                Tool(
                    name="get_stock_price",
                    description="è·å–è‚¡ç¥¨å®æ—¶ä»·æ ¼å’ŒåŸºæœ¬ä¿¡æ¯",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "ticker": {
                                "type": "string",
                                "description": "è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ AAPL, MSFTï¼‰"
                            },
                            "source": {
                                "type": "string",
                                "enum": ["auto", "yahoo", "alpha_vantage"],
                                "default": "auto",
                                "description": "æ•°æ®æºé€‰æ‹©ï¼ˆauto=è‡ªåŠ¨é€‰æ‹©æœ€ä½³ï¼‰"
                            }
                        },
                        "required": ["ticker"]
                    }
                ),
                Tool(
                    name="get_historical_data",
                    description="è·å–è‚¡ç¥¨å†å²ä»·æ ¼æ•°æ®",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "ticker": {"type": "string"},
                            "period": {
                                "type": "string",
                                "enum": ["1d", "5d", "1mo", "3mo", "6mo", "1y", "2y", "5y"],
                                "default": "1mo"
                            },
                            "interval": {
                                "type": "string",
                                "enum": ["1m", "5m", "15m", "1h", "1d", "1wk", "1mo"],
                                "default": "1d"
                            },
                            "source": {
                                "type": "string",
                                "enum": ["auto", "yahoo", "alpha_vantage"],
                                "default": "auto"
                            }
                        },
                        "required": ["ticker"]
                    }
                ),
                Tool(
                    name="get_fundamentals",
                    description="è·å–è‚¡ç¥¨åŸºæœ¬é¢æ•°æ®ï¼ˆä¼°å€¼ã€ç›ˆåˆ©èƒ½åŠ›ã€è´¢åŠ¡å¥åº·ç­‰ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "ticker": {"type": "string"},
                            "source": {
                                "type": "string",
                                "enum": ["auto", "yahoo", "alpha_vantage"],
                                "default": "auto"
                            }
                        },
                        "required": ["ticker"]
                    }
                ),
                Tool(
                    name="get_peer_comparison",
                    description="è·å–åŒè¡Œä¸šå…¬å¸ä¼°å€¼å¯¹æ¯”",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "ticker": {"type": "string"},
                            "source": {
                                "type": "string",
                                "enum": ["auto", "yahoo"],
                                "default": "auto"
                            }
                        },
                        "required": ["ticker"]
                    }
                ),
                Tool(
                    name="get_market_indices",
                    description="è·å–ä¸»è¦å¸‚åœºæŒ‡æ•°ï¼ˆS&P 500, NASDAQ, DOWç­‰ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "indices": {
                                "type": "array",
                                "items": {"type": "string"},
                                "default": ["^GSPC", "^IXIC", "^DJI"]
                            }
                        }
                    }
                ),
                Tool(
                    name="get_analyst_ratings",
                    description="è·å–åˆ†æå¸ˆè¯„çº§å’Œç›®æ ‡ä»·",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "ticker": {"type": "string"},
                            "source": {
                                "type": "string",
                                "enum": ["auto", "yahoo"],
                                "default": "auto"
                            }
                        },
                        "required": ["ticker"]
                    }
                ),
            ]
        
        @self.server.call_tool()
        async def call_tool(name: str, arguments: dict) -> List[TextContent]:
            """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
            logger.info(f"ğŸ”§ Tool called: {name} with args: {arguments}")
            
            try:
                # è·¯ç”±åˆ°å¯¹åº”çš„å¤„ç†å‡½æ•°
                if name == "get_stock_price":
                    result = await self._get_stock_price(**arguments)
                elif name == "get_historical_data":
                    result = await self._get_historical_data(**arguments)
                elif name == "get_fundamentals":
                    result = await self._get_fundamentals(**arguments)
                elif name == "get_peer_comparison":
                    result = await self._get_peer_comparison(**arguments)
                elif name == "get_market_indices":
                    result = await self._get_market_indices(**arguments)
                elif name == "get_analyst_ratings":
                    result = await self._get_analyst_ratings(**arguments)
                else:
                    raise ValueError(f"Unknown tool: {name}")
                
                # è¿”å›ç»“æœ
                return [TextContent(
                    type="text",
                    text=json.dumps(result, indent=2, default=str)
                )]
                
            except Exception as e:
                logger.error(f"âŒ Tool execution failed: {e}")
                return [TextContent(
                    type="text",
                    text=json.dumps({
                        "error": str(e),
                        "tool": name,
                        "arguments": arguments
                    }, indent=2)
                )]
    
    # ========== å·¥å…·å®ç°æ–¹æ³• ==========
    
    async def _get_stock_price(
        self, 
        ticker: str, 
        source: str = "auto"
    ) -> Dict[str, Any]:
        """
        è·å–è‚¡ç¥¨å®æ—¶ä»·æ ¼
        
        æ™ºèƒ½è·¯ç”±ç­–ç•¥ï¼š
        1. autoæ¨¡å¼ï¼šæŒ‰ä¼˜å…ˆçº§å°è¯•å„æ•°æ®æº
        2. æŒ‡å®šæºï¼šç›´æ¥è°ƒç”¨ç‰¹å®šæ•°æ®æº
        3. æ•…éšœè½¬ç§»ï¼šæŸä¸ªæºå¤±è´¥è‡ªåŠ¨åˆ‡æ¢
        """
        cache_key = f"stock_price:{ticker}:{source}"
        
        # æ£€æŸ¥ç¼“å­˜
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            logger.info(f"ğŸ“¦ Cache hit: {cache_key}")
            return cached_data
        
        # ç¡®å®šæ•°æ®æºåˆ—è¡¨
        if source == "auto":
            sources = mcp_settings.DATA_SOURCE_PRIORITY
        else:
            sources = [source]
        
        # å°è¯•å„æ•°æ®æº
        last_error = None
        for src in sources:
            try:
                adapter = self.adapters.get(src)
                if not adapter:
                    continue
                
                logger.info(f"ğŸ“¡ Fetching from {src}: {ticker}")
                data = await adapter.get_stock_price(ticker)
                
                if data:
                    # æ·»åŠ å…ƒæ•°æ®
                    data["_source"] = src
                    data["_timestamp"] = datetime.utcnow().isoformat()
                    
                    # ç¼“å­˜ç»“æœ
                    self._set_cache(cache_key, data)
                    
                    return data
                    
            except Exception as e:
                logger.warning(f"âš ï¸ {src} failed for {ticker}: {e}")
                last_error = e
                continue
        
        # æ‰€æœ‰æºéƒ½å¤±è´¥
        raise Exception(f"All data sources failed for {ticker}. Last error: {last_error}")
    
    async def _get_historical_data(
        self, 
        ticker: str,
        period: str = "1mo",
        interval: str = "1d",
        source: str = "auto"
    ) -> Dict[str, Any]:
        """è·å–å†å²æ•°æ®"""
        cache_key = f"historical:{ticker}:{period}:{interval}:{source}"
        
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            return cached_data
        
        sources = [source] if source != "auto" else mcp_settings.DATA_SOURCE_PRIORITY
        
        for src in sources:
            try:
                adapter = self.adapters.get(src)
                if not adapter:
                    continue
                
                data = await adapter.get_historical_data(ticker, period, interval)
                if data:
                    data["_source"] = src
                    data["_timestamp"] = datetime.utcnow().isoformat()
                    self._set_cache(cache_key, data)
                    return data
                    
            except Exception as e:
                logger.warning(f"âš ï¸ {src} historical data failed: {e}")
                continue
        
        raise Exception(f"Failed to fetch historical data for {ticker}")
    
    async def _get_fundamentals(
        self,
        ticker: str,
        source: str = "auto"
    ) -> Dict[str, Any]:
        """è·å–åŸºæœ¬é¢æ•°æ®"""
        cache_key = f"fundamentals:{ticker}:{source}"
        
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            return cached_data
        
        sources = [source] if source != "auto" else mcp_settings.DATA_SOURCE_PRIORITY
        
        for src in sources:
            try:
                adapter = self.adapters.get(src)
                if not adapter:
                    continue
                
                data = await adapter.get_fundamentals(ticker)
                if data:
                    data["_source"] = src
                    data["_timestamp"] = datetime.utcnow().isoformat()
                    self._set_cache(cache_key, data)
                    return data
                    
            except Exception as e:
                logger.warning(f"âš ï¸ {src} fundamentals failed: {e}")
                continue
        
        raise Exception(f"Failed to fetch fundamentals for {ticker}")
    
    async def _get_peer_comparison(
        self,
        ticker: str,
        source: str = "auto"
    ) -> Dict[str, Any]:
        """è·å–åŒè¡Œå¯¹æ¯”"""
        cache_key = f"peer_comparison:{ticker}:{source}"
        
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            return cached_data
        
        # ç›®å‰åªæœ‰Yahooæ”¯æŒ
        adapter = self.adapters.get("yahoo")
        data = await adapter.get_peer_comparison(ticker)
        
        if data:
            data["_source"] = "yahoo"
            data["_timestamp"] = datetime.utcnow().isoformat()
            self._set_cache(cache_key, data)
            return data
        
        raise Exception(f"Failed to fetch peer comparison for {ticker}")
    
    async def _get_market_indices(
        self,
        indices: List[str] = None
    ) -> Dict[str, Any]:
        """è·å–å¸‚åœºæŒ‡æ•°"""
        if indices is None:
            indices = ["^GSPC", "^IXIC", "^DJI"]  # S&P 500, NASDAQ, DOW
        
        cache_key = f"market_indices:{':'.join(sorted(indices))}"
        
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            return cached_data
        
        # å¹¶è¡Œè·å–æ‰€æœ‰æŒ‡æ•°
        adapter = self.adapters.get("yahoo")
        
        tasks = [adapter.get_stock_price(idx) for idx in indices]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        indices_data = {}
        for idx, result in zip(indices, results):
            if isinstance(result, Exception):
                logger.warning(f"âš ï¸ Failed to fetch {idx}: {result}")
                continue
            indices_data[idx] = result
        
        data = {
            "indices": indices_data,
            "_timestamp": datetime.utcnow().isoformat(),
            "_source": "yahoo"
        }
        
        self._set_cache(cache_key, data)
        return data
    
    async def _get_analyst_ratings(
        self,
        ticker: str,
        source: str = "auto"
    ) -> Dict[str, Any]:
        """è·å–åˆ†æå¸ˆè¯„çº§"""
        cache_key = f"analyst_ratings:{ticker}:{source}"
        
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            return cached_data
        
        adapter = self.adapters.get("yahoo")
        data = await adapter.get_analyst_ratings(ticker)
        
        if data:
            data["_source"] = "yahoo"
            data["_timestamp"] = datetime.utcnow().isoformat()
            self._set_cache(cache_key, data)
            return data
        
        raise Exception(f"Failed to fetch analyst ratings for {ticker}")
    
    # ========== ç¼“å­˜è¾…åŠ©æ–¹æ³• ==========
    
    def _get_from_cache(self, cache_key: str) -> Optional[Dict]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        if not mcp_settings.MCP_ENABLE_CACHE:
            return None
        
        if cache_key in self.cache:
            data, timestamp = self.cache[cache_key]
            age = datetime.utcnow().timestamp() - timestamp
            
            if age < mcp_settings.MCP_CACHE_TTL:
                return data
            else:
                del self.cache[cache_key]
        
        return None
    
    def _set_cache(self, cache_key: str, data: Dict):
        """è®¾ç½®ç¼“å­˜"""
        if mcp_settings.MCP_ENABLE_CACHE:
            self.cache[cache_key] = (data, datetime.utcnow().timestamp())
    
    async def run(self):
        """è¿è¡ŒMCPæœåŠ¡å™¨ï¼ˆstdioæ¨¡å¼ï¼‰"""
        logger.info("ğŸš€ Starting Financial Data MCP Server...")
        async with stdio_server() as (read_stream, write_stream):
            await self.server.run(
                read_stream,
                write_stream,
                self.server.create_initialization_options()
            )
 
 
# ä¸»å‡½æ•°
async def main():
    server = FinancialDataMCPServer()
    await server.run()
 
 
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())